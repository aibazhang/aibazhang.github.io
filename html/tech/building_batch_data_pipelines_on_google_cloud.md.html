<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.13.2/dist/style.min.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@6.7.0"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.13.5"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.13.2/dist/index.umd.min.js"></script><script>(r => {
          setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{"type":"heading","depth":0,"payload":{"lines":[0,1]},"content":"Building Batch Data Pipelines on Google Cloud","children":[{"type":"heading","depth":1,"payload":{"lines":[2,3]},"content":"EL, ELT, ETL","children":[{"type":"heading","depth":2,"payload":{"lines":[4,5]},"content":"EL","children":[{"type":"list_item","depth":3,"payload":{"lines":[6,7]},"content":"when data can be imported as is into a system"},{"type":"list_item","depth":3,"payload":{"lines":[7,8]},"content":"<strong>if the data is already clean and correct</strong>"},{"type":"list_item","depth":3,"payload":{"lines":[8,9]},"content":"batch load of historical data, scheudled periodic loads of log files (e.g once a day)"},{"type":"list_item","depth":3,"payload":{"lines":[9,10]},"content":"Architecture","children":[{"type":"list_item","depth":4,"payload":{"lines":[10,11]},"content":"Extract data from files on Cloud Storage"},{"type":"list_item","depth":4,"payload":{"lines":[11,12]},"content":"Load it into BigQuery's native storage"},{"type":"list_item","depth":4,"payload":{"lines":[12,13]},"content":"You can trigger this from Cloud Composer, Cloud Functions, or scheduled queries"}]}]},{"type":"heading","depth":2,"payload":{"lines":[14,15]},"content":"ELT","children":[{"type":"list_item","depth":3,"payload":{"lines":[16,17]},"content":"EL + transformed whennever it is needed"},{"type":"list_item","depth":3,"payload":{"lines":[17,18]},"content":"experimental datasets where you are not yet sure what kinds of transformations are needed to make the data useable"},{"type":"list_item","depth":3,"payload":{"lines":[18,19]},"content":"any production dataset where the transformation can be expressed in SQL"},{"type":"list_item","depth":3,"payload":{"lines":[19,20]},"content":"Architecture","children":[{"type":"list_item","depth":4,"payload":{"lines":[20,21]},"content":"Transform the data on the fly using BigQuery views, or store into new tables"}]}]},{"type":"heading","depth":2,"payload":{"lines":[22,23]},"content":"ETL","children":[{"type":"list_item","depth":3,"payload":{"lines":[24,25]},"content":"if the transformations cannot be expressed in SQL, or are too complex to do in SQL"},{"type":"list_item","depth":3,"payload":{"lines":[25,26]},"content":"when the raw data needs to be quality-controlled transformed, or enriched before being loaded into BigQuery"},{"type":"list_item","depth":3,"payload":{"lines":[26,27]},"content":"when you want to intgrate with CI/CD systems and perform unit testing on all components"},{"type":"list_item","depth":3,"payload":{"lines":[27,28]},"content":"Architecture","children":[{"type":"list_item","depth":4,"payload":{"lines":[28,29]},"content":"Extract data from Pub/Sub, Cloud Storage, Cloud Spanner, Cloud SQL, etc."},{"type":"list_item","depth":4,"payload":{"lines":[29,30]},"content":"Transform the data using Dataflow"},{"type":"list_item","depth":4,"payload":{"lines":[30,31]},"content":"Have Dataflow pipeline write to BigQuery"}]}]},{"type":"heading","depth":2,"payload":{"lines":[32,33]},"content":"Quality Issues","children":[{"type":"list_item","depth":3,"payload":{"lines":[34,35]},"content":"Issue","children":[{"type":"list_item","depth":4,"payload":{"lines":[35,36]},"content":"Latency, throughput: Dataflow to Bigtable"},{"type":"list_item","depth":4,"payload":{"lines":[36,37]},"content":"Reusing Spark pipeliens: Dataproc"},{"type":"list_item","depth":4,"payload":{"lines":[37,38]},"content":"Need for visual pipline building: Cloud Data Fusion"}]},{"type":"list_item","depth":3,"payload":{"lines":[38,39]},"content":"Tracking lineage in ETL pipelines can be important","children":[{"type":"list_item","depth":4,"payload":{"lines":[39,40]},"content":"Discovery: find the data you need"},{"type":"list_item","depth":4,"payload":{"lines":[40,41]},"content":"Lineage: metadata about the data -&gt; Data Catalog"}]},{"type":"list_item","depth":3,"payload":{"lines":[41,42]},"content":"Data catalog","children":[{"type":"list_item","depth":4,"payload":{"lines":[42,43]},"content":"Simplify data discovery at any scale","children":[{"type":"list_item","depth":5,"payload":{"lines":[43,44]},"content":"Fully managed metadata management service with no infrastructure to set up or manage"}]},{"type":"list_item","depth":4,"payload":{"lines":[44,45]},"content":"Unified view of all datasets","children":[{"type":"list_item","depth":5,"payload":{"lines":[45,46]},"content":"Central and secure data catalog across Google Cloud with metadata capture and tagging"}]},{"type":"list_item","depth":4,"payload":{"lines":[46,47]},"content":"Data governance foundation","children":[{"type":"list_item","depth":5,"payload":{"lines":[47,48]},"content":"Security compliance with access level controls along with Cloud Data Loss Prevention integration for handling sensitive data"}]}]}]}]},{"type":"heading","depth":1,"payload":{"lines":[49,50]},"content":"Executing Spark on Dataproc","children":[{"type":"list_item","depth":2,"payload":{"lines":[51,52]},"content":"history","children":[{"type":"list_item","depth":3,"payload":{"lines":[52,53]},"content":"~2006 Database","children":[{"type":"list_item","depth":4,"payload":{"lines":[53,54]},"content":"bring the data to the processor"}]},{"type":"list_item","depth":3,"payload":{"lines":[54,55]},"content":"2006~2010s Hadoop","children":[{"type":"list_item","depth":4,"payload":{"lines":[55,56]},"content":"destibute the processing"},{"type":"list_item","depth":4,"payload":{"lines":[56,57]},"content":"store the data with the processors"}]},{"type":"list_item","depth":3,"payload":{"lines":[57,58]},"content":"2010s~ Cloud services","children":[{"type":"list_item","depth":4,"payload":{"lines":[58,59]},"content":"separate, specialize, and connect"},{"type":"list_item","depth":4,"payload":{"lines":[59,60]},"content":"data storage services"},{"type":"list_item","depth":4,"payload":{"lines":[60,61]},"content":"data procesing services"},{"type":"list_item","depth":4,"payload":{"lines":[61,62]},"content":"messaging services"}]}]},{"type":"list_item","depth":2,"payload":{"lines":[62,63]},"content":"Google Cloud provides different storage options for different jobs","children":[{"type":"list_item","depth":3,"payload":{"lines":[63,64]},"content":"Cloud Storage","children":[{"type":"list_item","depth":4,"payload":{"lines":[64,65]},"content":"primary datastore for google cloud"},{"type":"list_item","depth":4,"payload":{"lines":[65,66]},"content":"unstructured data"}]},{"type":"list_item","depth":3,"payload":{"lines":[66,67]},"content":"cloud bigtable","children":[{"type":"list_item","depth":4,"payload":{"lines":[67,68]},"content":"large amounts of sparse data"},{"type":"list_item","depth":4,"payload":{"lines":[68,69]},"content":"HBase-compliant"},{"type":"list_item","depth":4,"payload":{"lines":[69,70]},"content":"low latency"},{"type":"list_item","depth":4,"payload":{"lines":[70,71]},"content":"high scalability"}]},{"type":"list_item","depth":3,"payload":{"lines":[71,72]},"content":"BigQuery","children":[{"type":"list_item","depth":4,"payload":{"lines":[72,73]},"content":"data warehousing"},{"type":"list_item","depth":4,"payload":{"lines":[73,74]},"content":"storage API makes this faster than before"},{"type":"list_item","depth":4,"payload":{"lines":[74,75]},"content":"cloud push down queries to BigQuery refactoring the job"}]}]}]},{"type":"heading","depth":1,"payload":{"lines":[77,78]},"content":"Run batch processsing pipelines on Dataflow","children":[{"type":"list_item","depth":2,"payload":{"lines":[79,80]},"content":"Dataflow vs. Dataproc","children":[{"type":"list_item","depth":3,"payload":{"lines":[80,81]},"content":"Dataflow","children":[{"type":"list_item","depth":4,"payload":{"lines":[81,82]},"content":"New data processing pipelines, unfied batch and straming"},{"type":"list_item","depth":4,"payload":{"lines":[82,83]},"content":"Auto-scaling: transform-by-transform (adaptive)"}]},{"type":"list_item","depth":3,"payload":{"lines":[83,84]},"content":"Dataproc","children":[{"type":"list_item","depth":4,"payload":{"lines":[84,85]},"content":"Existing Hadoop/Spark applications, machine learning/data science ecosystem large-batch jobs, preemptible VMs"},{"type":"list_item","depth":4,"payload":{"lines":[85,86]},"content":"Auto-scaling: based on cluster utilization (reactive)"}]}]},{"type":"list_item","depth":2,"payload":{"lines":[86,87]},"content":"Apache BEAM = Batch + Stream"}]}]},null)</script>
</body>
</html>
